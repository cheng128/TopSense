{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/evaluation_sample.json') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import pickle\n",
    "from random import sample \n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "model = pipeline('fill-mask',\n",
    "                 model=f\"../model/brt/remap_10epochs\",\n",
    "                 tokenizer=\"../remap_topic_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_voa():\n",
    "    with open('./data/voa_sentence.json') as f:\n",
    "        voa_sentences = json.loads(f.read())\n",
    "    return voa_sentences\n",
    "\n",
    "def handle_examples(headword, sent_en):\n",
    "    reconstruct = []\n",
    "    doc = nlp(sent_en)\n",
    "    \n",
    "    word = ''\n",
    "    find = False\n",
    "    for token in doc:\n",
    "        if not find:\n",
    "            if token.text == headword and token.pos_ in ['PROPN', 'NOUN'] and not token.is_stop:\n",
    "                word = token.text\n",
    "                find = True\n",
    "            elif token.lemma_ == headword and token.pos_ in ['PROPN', 'NOUN'] and not token.is_stop:\n",
    "                word = token.lemma_\n",
    "                find = True\n",
    "\n",
    "            if find:\n",
    "                reconstruct.append('[MASK]')\n",
    "                continue\n",
    "        else:\n",
    "            reconstruct.append(token.text)\n",
    "            \n",
    "    masked_sent = ' '.join(reconstruct)\n",
    "    return masked_sent \n",
    "\n",
    "def load_spacy_sbert():\n",
    "    model = SentenceTransformer('all-roberta-large-v1')\n",
    "    spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "    return model, spacy_model\n",
    "\n",
    "def load_cambridge():\n",
    "    with open('../data/words2defs.json') as f:\n",
    "        word2defs = json.loads(f.read())\n",
    "        \n",
    "    with open('../data/def2guide.json') as f:\n",
    "        def2guideword = json.loads(f.read())\n",
    "    return word2defs, def2guideword\n",
    "\n",
    "def load_map():\n",
    "    with open('../data/orig_new.json') as f:\n",
    "        data = json.loads(f.read())\n",
    "        \n",
    "    with open('../data/topic_embs.pickle', 'rb') as f:\n",
    "        emb_map = pickle.load(f)\n",
    "    return data, emb_map\n",
    "\n",
    "def disambiguate(sent, targetword, token_score, word2defs, def2guideword, cat_map, emb_map):\n",
    "    definitions = word2defs[nlp(targetword)[0].lemma_]\n",
    "\n",
    "    # sentence and definitions\n",
    "    sentence_defs = [sent.replace('[MASK]', targetword)]\n",
    "    sentence_defs.extend(definitions)\n",
    "    embs = sbert.encode(sentence_defs, convert_to_tensor=True)\n",
    "    # calculate cosine similarity score\n",
    "    cos_scores = util.pytorch_cos_sim(embs, embs)\n",
    "    \n",
    "    defs_score = {}\n",
    "    i = 0\n",
    "    for j in range(1, len(cos_scores)):\n",
    "        defs_score[sentence_defs[j]]  = cos_scores[i][j] \n",
    "\n",
    "    topic_defs = {}\n",
    "    for result in token_score:\n",
    "        embs = sbert.encode(definitions, convert_to_tensor=True)\n",
    "        if result in emb_map:\n",
    "            cosine_scores = util.pytorch_cos_sim(embs, emb_map[result])\n",
    "            pairs = []\n",
    "            edge = len(definitions)\n",
    "            for i in range(0, edge):\n",
    "                for j in range(0, len(emb_map[result])):\n",
    "                    pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "            pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "            highest_idx = pairs[0]['index'][0]\n",
    "            topic_defs[result] = [definitions[highest_idx], pairs[0]['score']]\n",
    "    \n",
    "    result = []\n",
    "    for idx, topic in enumerate(token_score):\n",
    "        if topic in topic_defs:\n",
    "            sense = topic_defs[topic][0]\n",
    "            result.append([sense, (token_score[topic] * topic_defs[topic][1]) + defs_score[sense]/2])\n",
    "    result = sorted(result, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    ans_score = {}\n",
    "    for i in result:\n",
    "        if i[0] not in ans_score:\n",
    "            ans_score[i[0]] = [i[1]]\n",
    "        else:\n",
    "            ans_score[i[0]].append(i[1])\n",
    "            \n",
    "    confidence = []\n",
    "    for k, v in ans_score.items():\n",
    "        confidence.append([k, sum(v)/len(v)])\n",
    "    confidence = sorted(confidence, key=lambda x: x[1], reverse=True)\n",
    "    confidence = [str(i) for i in confidence]\n",
    "    return confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_examples('taste', \"They include changing public tastes, high operating costs, and public battles with animal rights groups. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert, spacy_model = load_spacy_sbert()\n",
    "voa_sentence = load_voa()\n",
    "orig_new_map, emb_map = load_map()\n",
    "word2defs, def2guideword = load_cambridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/voa_evaluation_10.tsv', 'a') as f:\n",
    "    for k, v in voa_sentence.items():\n",
    "        for sent in v:\n",
    "            masked_sent = handle_examples(k, sent)\n",
    "            try:\n",
    "                results = model(masked_sent)\n",
    "            except:\n",
    "                print(sent)\n",
    "                print(masked_sent)\n",
    "            token_score = {line['token_str'][1:-1]: line['score'] for line in results}\n",
    "            token = '\\t'.join(token_score.keys())\n",
    "            senses = disambiguate(sent, k, token_score, word2defs, def2guideword, orig_new_map, emb_map)\n",
    "            senses = '\\t'.join([str(i) for i in senses])\n",
    "            f.write(sent.strip() + '\\t' + token + '\\t' + senses + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/voa_sentences.json') as f:\n",
    "    voa_sentences = json.loads(f.read())\n",
    "\n",
    "voa_sample = {}\n",
    "for k, v in voa_sentences.items():\n",
    "    \n",
    "    if len(v) > 10:\n",
    "        v = list(set(v))\n",
    "        v = sorted(v, key=lambda x: len(x.split()), reverse=True)\n",
    "        sent = [line for line in v if len(line.split())<20 and len(line.split())>10][5:15]\n",
    "    else:\n",
    "        sent = v\n",
    "    voa_sample[k] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/voa_sample.json', 'w') as f:\n",
    "#     f.write(json.dumps(voa_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A current employee said the bank could soon test facial recognition software on people as they enter a bank.\\n',\n",
       " 'The delegates have promised to work on issues including water and property rights, central bank independence and labor policies.\\n',\n",
       " 'But Vitezâ€™s biggest concern is whether some schools may urge students towards banks that may harm them financially.\\n',\n",
       " 'He said a big question for banks with this technology is how the public will react to it.\\n',\n",
       " 'The man told Schuster that the Air Force would not let him remove money from his bank account.\\n',\n",
       " 'Treasury Department said it will work with banks and technology companies to avoid becoming victims of ransomware attacks.\\n',\n",
       " 'The newspaper said Borghese wrote checks to people although he did not have enough money in the bank.\\n',\n",
       " 'They said the government acted because of fears that the crisis would cause a run on the banks.\\n',\n",
       " 'Or, they may be charged fees if they spend more money than they have in their bank accounts.\\n',\n",
       " 'Language barriers and limited relationships with banks have made it harder for them to learn about government aid.\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa_sample['bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/MED.json') as f:\n",
    "    med = json.loads(f.read())\n",
    "\n",
    "# with open('./data/evaluation_sample.json') as f:\n",
    "#     sample = json.loads(f.read())\n",
    "    \n",
    "# with open('./data/voa_sentences.json') as f:\n",
    "#     voa = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = defaultdict(list)\n",
    "for word in voa.keys():\n",
    "    count = 0\n",
    "    for sense in med[word]['noun']['SENSE']:\n",
    "        examples = [line[0] for line in sense[-1]]\n",
    "        evaluation[word].extend(examples)\n",
    "        count += len(examples)\n",
    "    if count > 10:\n",
    "        over.append(word)\n",
    "\n",
    "for word, value in evaluation.items():\n",
    "    if len(value) < 10:\n",
    "        evaluation[word] += sample[word][:10-len(evaluation[word])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_sep = defaultdict(dict)\n",
    "for word in over:\n",
    "    for idx, sense in enumerate(med[word]['noun']['SENSE']):\n",
    "        examples = [line[0] for line in sense[-1]]\n",
    "        sense_sep[word][idx] = examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste\n",
      "interest\n",
      "star\n"
     ]
    }
   ],
   "source": [
    "for word in sense_sep:\n",
    "    print(word)\n",
    "    evaluation[word] = []\n",
    "    count = 10\n",
    "    while count > 0:\n",
    "        for idx, sents in sense_sep[word].items():\n",
    "            if sents:\n",
    "                sents = sorted(sents, key=lambda x:len(x.split()), reverse=True)\n",
    "                evaluation[word].append(sents[0])\n",
    "                sense_sep[word][idx].pop(0)\n",
    "                count -= 1\n",
    "                if count == 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste\n",
      "10\n",
      "issue\n",
      "10\n",
      "interest\n",
      "10\n",
      "star\n",
      "10\n",
      "duty\n",
      "10\n",
      "sentence\n",
      "10\n",
      "cone\n",
      "10\n",
      "bow\n",
      "9\n",
      "mole\n",
      "10\n",
      "slug\n",
      "10\n",
      "bass\n",
      "5\n",
      "bank\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for k, v in evaluation.items():\n",
    "    print(k)\n",
    "    print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'super_group': 'Foundations of Knowledge', 'category': 'Mathematics', 'pos': 'noun', 'brt_word': 'cone', 'group': '43', 'word_id': 'cone.noun.01', 'en_def': 'a shape with a flat, round or oval base and a top that becomes narrower until it forms a point', 'score': 0.449418306350708}\n",
      "\n",
      "{'super_group': 'Living Things', 'category': 'Human Body', 'pos': 'noun', 'brt_word': 'cone', 'group': '9', 'word_id': 'cone.noun.01', 'en_def': 'a shape with a flat, round or oval base and a top that becomes narrower until it forms a point', 'score': 0.4992419183254242}\n",
      "\n",
      "{'super_group': 'Living Things', 'category': 'Trees', 'pos': 'noun', 'brt_word': 'pine cone', 'group': '2', 'word_id': 'pine-cone.noun.01', 'en_def': 'the hard, egg-shaped part of the pine tree that opens and releases seeds', 'score': 'one_sense'}\n",
      "\n",
      "{'super_group': 'Living Things', 'category': 'Trees', 'pos': 'noun', 'brt_word': 'cone', 'group': '2', 'word_id': 'cone.noun.02', 'en_def': 'the hard oval-shaped fruit of a conifer', 'score': 0.6884533762931824}\n",
      "\n",
      "{'super_group': 'Provision', 'category': 'Food', 'pos': 'noun', 'brt_word': 'scone', 'group': '37', 'word_id': 'scone.noun.01', 'en_def': 'a small, round cake that is like bread, made from flour, milk, and a little fat', 'score': 'one_sense'}\n",
      "\n",
      "{'super_group': 'The Senses', 'category': 'Vision', 'pos': 'noun', 'brt_word': 'cone', 'group': '3', 'word_id': 'cone.noun.01', 'en_def': 'a shape with a flat, round or oval base and a top that becomes narrower until it forms a point', 'score': 0.476438969373703}\n",
      "\n",
      "{'super_group': 'Material Characteristics', 'category': 'Oiliness, Lubrication', 'pos': 'noun', 'brt_word': 'silicone', 'group': '7', 'word_id': 'silicone.noun.01', 'en_def': 'any of a number of compounds of silicon that are used in making artificial rubber, paint, polish, varnish, etc.', 'score': 'one_sense'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/0.0_top3_brt_map_cam.jsonl') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "for line in data:\n",
    "    if 'cone.noun' in line['word_id']:\n",
    "        print(line)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/med_voa_sample.json', 'w') as f:\n",
    "    f.write(json.dumps(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/med2cam_sense.noun.json') as f:\n",
    "    med2cam = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in med2cam:\n",
    "    for sense in med2cam[word]:\n",
    "        examples = sense2examples[sense['med_def']]\n",
    "        sense['examples'] = examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense2examples = {}\n",
    "for word in med:\n",
    "    if 'noun' in med[word]:\n",
    "        for sense in med[word]['noun']['SENSE']:\n",
    "            en_sense = sense[0]\n",
    "            examples = [line[0] for line in sense[-1]]\n",
    "            sense2examples[en_sense] = examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a fish that lives in rivers and the sea', 'é±¸é­š', []]\n"
     ]
    }
   ],
   "source": [
    "for i in med['bass']['noun']['SENSE']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/voa_sentences.json') as f:\n",
    "    voa = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['taste', 'issue', 'interest', 'star', 'duty', 'sentence', 'cone', 'bow', 'mole', 'slug', 'bass', 'bank'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voa.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for word in voa.keys():\n",
    "    for sense in med2cam[word]:\n",
    "        print(sense)\n",
    "        print(sense['examples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/med2cam_sense.noun.json') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'med_sense': 'a financial institution that people or businesses can keep their money in or borrow money from. The main banks used by ordinary people are called high-street banks', 'cam_sense': 'an organization where people and businesses can invest or borrow money, change it to foreign money, etc., or a building where these services are offered', 'examples': ['Marge works for the Royal Bank of Scotland.', 'a New York investment bank'], 'avg_score': 0.3191983103752136}\n",
      "\n",
      "{'med_sense': 'a raised area of land along the side of a river', 'cam_sense': 'sloping raised land, especially along the sides of a river', 'examples': ['A man was fishing on the opposite bank.', 'The village lies on the east bank of the river Derwent.'], 'avg_score': 0.4779926836490631}\n",
      "\n",
      "{'med_sense': 'a large number of things in a row, especially pieces of equipment', 'cam_sense': 'a row of similar things, especially machines or parts of machines', 'examples': ['a bank of TV monitors'], 'avg_score': 0.4837077260017395}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data['bank']:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graduate",
   "language": "python",
   "name": "graduate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
