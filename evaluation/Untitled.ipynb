{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/remap.word_id.topics.examples.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23387/2770492827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/remap.word_id.topics.examples.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mid2topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/remap.word_id.topics.examples.json'"
     ]
    }
   ],
   "source": [
    "with open('./data/remap.word_id.topics.examples.json') as f:\n",
    "    id2topics = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/voa_sentences.json') as f:\n",
    "    voa_sentences = json.loads(f.read())\n",
    "\n",
    "voa_sample = {}\n",
    "for k, v in voa_sentences.items():\n",
    "    \n",
    "    if len(v) > 10:\n",
    "        v = list(set(v))\n",
    "        v = sorted(v, key=lambda x: len(x.split()), reverse=True)\n",
    "        sent = [line for line in v if len(line.split()) < 30 and len(line.split())>10][:10]\n",
    "    else:\n",
    "        sent = v\n",
    "    voa_sample[k] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/voa_sample.json', 'w') as f:\n",
    "#     f.write(json.dumps(voa_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/MED.json') as f:\n",
    "    med = json.loads(f.read())\n",
    "\n",
    "# with open('./data/evaluation_sample.json') as f:\n",
    "#     sample = json.loads(f.read())\n",
    "    \n",
    "# with open('./data/voa_sentences.json') as f:\n",
    "#     voa = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = defaultdict(list)\n",
    "for word in voa.keys():\n",
    "    count = 0\n",
    "    for sense in med[word]['noun']['SENSE']:\n",
    "        examples = [line[0] for line in sense[-1]]\n",
    "        evaluation[word].extend(examples)\n",
    "        count += len(examples)\n",
    "    if count > 10:\n",
    "        over.append(word)\n",
    "\n",
    "for word, value in evaluation.items():\n",
    "    if len(value) < 10:\n",
    "        evaluation[word] += sample[word][:10-len(evaluation[word])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_sep = defaultdict(dict)\n",
    "for word in over:\n",
    "    for idx, sense in enumerate(med[word]['noun']['SENSE']):\n",
    "        examples = [line[0] for line in sense[-1]]\n",
    "        sense_sep[word][idx] = examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sense_sep:\n",
    "    print(word)\n",
    "    evaluation[word] = []\n",
    "    count = 10\n",
    "    while count > 0:\n",
    "        for idx, sents in sense_sep[word].items():\n",
    "            if sents:\n",
    "                sents = sorted(sents, key=lambda x:len(x.split()), reverse=True)\n",
    "                evaluation[word].append(sents[0])\n",
    "                sense_sep[word][idx].pop(0)\n",
    "                count -= 1\n",
    "                if count == 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in evaluation.items():\n",
    "    print(k)\n",
    "    print(len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/0.0_top3_brt_map_cam.jsonl') as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "for line in data:\n",
    "    if 'cone.noun' in line['word_id']:\n",
    "        print(line)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/med_voa_sample.json', 'w') as f:\n",
    "    f.write(json.dumps(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/med2cam_sense.noun.json') as f:\n",
    "    med2cam = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in med2cam:\n",
    "    for sense in med2cam[word]:\n",
    "        examples = sense2examples[sense['med_def']]\n",
    "        sense['examples'] = examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense2examples = {}\n",
    "for word in med:\n",
    "    if 'noun' in med[word]:\n",
    "        for sense in med[word]['noun']['SENSE']:\n",
    "            en_sense = sense[0]\n",
    "            examples = [line[0] for line in sense[-1]]\n",
    "            sense2examples[en_sense] = examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From med sentences + voa sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/med_sentences.json') as f:\n",
    "    med = json.loads(f.read())\n",
    "    \n",
    "with open('./data/voa_sentences.json') as f:\n",
    "    voa = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste\n",
      "issue\n",
      "interest\n",
      "star\n",
      "duty\n",
      "sentence\n",
      "cone\n",
      "bow\n",
      "slug\n",
      "bank\n",
      "mole\n",
      "bass\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = {}\n",
    "voa_left_sent = {}\n",
    "\n",
    "for word, value in med.items():\n",
    "    print(word)\n",
    "    examples = [sent[0] for data in value \n",
    "                for sent in data['examples']]\n",
    "    evaluation_data[word] = examples\n",
    "    if len(examples) < 30:\n",
    "        left = 30 - len(examples)\n",
    "        sentences = voa[word]\n",
    "        if left > len(sentences):\n",
    "            evaluation_data[word].extend(sentences)\n",
    "        else:\n",
    "            sentences = [line.replace('\\n', '') for line in voa[word]\n",
    "                        if len(line.split()) < 30]\n",
    "            voa_left_sent[word] = sentences\n",
    "            extend_sents = random.sample(sentences, left)\n",
    "            evaluation_data[word].extend(extend_sents)\n",
    "            for sent in extend_sents:\n",
    "                voa_left_sent[word].remove(sent)\n",
    "                \n",
    "for word in voa:\n",
    "    if word not in med:\n",
    "        print(word)\n",
    "        if len(voa[word]) < 30:\n",
    "            sents = voa[word]\n",
    "        else:\n",
    "            sentences = [line.replace('\\n', '') for line in voa[word]\n",
    "                        if len(line.split()) < 30]\n",
    "            voa_left_sent[word] = sentences\n",
    "            \n",
    "            sents = random.sample(sentences, 30)\n",
    "            for sent in sents:\n",
    "                voa_left_sent[word].remove(sent)\n",
    "        evaluation_data[word] = sents\n",
    "\n",
    "count = 0\n",
    "thirty = 0\n",
    "for k, v in evaluation_data.items():\n",
    "    count += len(v)\n",
    "    if len(v) == 30:\n",
    "        thirty += 1\n",
    "left = (300 - count) \n",
    "avg = left // thirty\n",
    "\n",
    "left_count_map = {}\n",
    "for k, v in evaluation_data.items():\n",
    "    if len(v) == 30:\n",
    "        left_count_map[k] = avg\n",
    "\n",
    "number = left % thirty\n",
    "while number > 0:\n",
    "    for word in left_count_map:\n",
    "        left_count_map[word] += 1\n",
    "    number -= len(left_count_map)\n",
    "\n",
    "for word, num in left_count_map.items():\n",
    "    sentences = voa_left_sent[word]\n",
    "    extend_sents = random.sample(sentences, num)\n",
    "    evaluation_data[word].extend(extend_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "thirty = 0\n",
    "for k, v in evaluation_data.items():\n",
    "    count += len(v)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['taste', 'issue', 'interest', 'star', 'duty', 'sentence', 'cone', 'bow', 'slug', 'bank', 'mole', 'bass'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/300_sentences.json', 'w') as f:\n",
    "    f.write(json.dumps(evaluation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graduate",
   "language": "python",
   "name": "graduate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
