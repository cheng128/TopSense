{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 med + voa sentences from 300 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/MED.json') as f:\n",
    "    med_data = json.loads(f.read())\n",
    "    \n",
    "with open('./data/voa_sentences.json') as f:\n",
    "    voa_sentences = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2ans = {}\n",
    "med_sents = {}\n",
    "word_sense = defaultdict(list)\n",
    "for word in voa_sentences:\n",
    "    for sense in med_data[word]['noun']['SENSE']:\n",
    "        definition = sense[1] + ' ' + sense[0]\n",
    "        examples = sense[-1]\n",
    "        word_sense[word].append(definition)\n",
    "        for sent in examples:\n",
    "            sent2ans[sent[0]] = definition \n",
    "        med_sents[definition] = sorted([sent[0] for sent in examples],\n",
    "                                        key=lambda x: len(x.split()), \n",
    "                                        reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/300_sentences.json') as f:\n",
    "    evaluation_300 = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NUM = 120\n",
    "WORDS_LIST = list(voa_sentences.keys())\n",
    "\n",
    "med_sentences = {}\n",
    "evaluation_sents = defaultdict(list)\n",
    "AVG_NUM = math.ceil(TARGET_NUM / len(WORDS_LIST))\n",
    "\n",
    "\n",
    "for word, examples in evaluation_300.items():\n",
    "    med_examples = [[sent, sent2ans[sent]] \n",
    "                   for sent in examples if sent in sent2ans]\n",
    "    med_sentences[word] = med_examples\n",
    "    \n",
    "    # deal with words that do not have examples\n",
    "    if not med_examples:\n",
    "        # if all voa_sentences do not enough then we add all sentences\n",
    "        if len(voa_sentences[word]) <= AVG_NUM:\n",
    "            evaluation_sents[word] = [[sent.replace('\\n', ''), '']\n",
    "                                      for sent in voa_sentences[word]]\n",
    "            TARGET_NUM -= len(evaluation_sents[word])\n",
    "            WORDS_LIST.remove(word)\n",
    "        else:\n",
    "            voa_examples = [[sent.replace('\\n', '' ), '']\n",
    "                            for sent in voa_sentences[word]]\n",
    "            evaluation_sents[word] = random.sample(voa_examples, 10)\n",
    "            TARGET_NUM -= len(evaluation_sents[word])\n",
    "            WORDS_LIST.remove(word)\n",
    "\n",
    "for word in WORDS_LIST:\n",
    "    examples = med_sentences[word]\n",
    "    if len(examples) <= AVG_NUM:\n",
    "        left = AVG_NUM - len(examples)\n",
    "        evaluation_sents[word] = examples\n",
    "        if left > 0:\n",
    "            voa_examples = [[sent.replace('\\n', ''), ''] \n",
    "                            for sent in voa_sentences[word]]\n",
    "            if len(voa_examples) > left:\n",
    "                voa_examples = random.sample(voa_examples, left)\n",
    "            evaluation_sents[word].extend(voa_examples)\n",
    "    else:\n",
    "        temp = AVG_NUM\n",
    "        while temp > 0:\n",
    "            for sense in word_sense[word]:\n",
    "                examples = med_sents[sense]\n",
    "                if examples:\n",
    "                    sent = examples[0]\n",
    "                    ans = sent2ans[sent]\n",
    "                    evaluation_sents[word].append([sent, ans])\n",
    "                    med_sents[sense] = examples[1:]\n",
    "                    temp -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check total number of sentences\n",
    "\"\"\"\n",
    "def check_count(dictionary):\n",
    "    count = 0\n",
    "    for key, value in dictionary.items():\n",
    "        print(key, len(value))\n",
    "        count += len(value) \n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count(evaluation_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/100_sentences.json', 'w') as f:\n",
    "#     f.write(json.dumps(evaluation_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other 200 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/100_sentences.json') as f:\n",
    "    evaluation_sents = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_200sents = defaultdict(list)\n",
    "\n",
    "WORDS_LIST = list(voa_sentences.keys())\n",
    "TARGET_NUM = 200\n",
    "AVG_NUM = math.ceil(TARGET_NUM / len(WORDS_LIST))\n",
    "\n",
    "exists_sents = {word: [sent[0] for sent in evaluation_sents[word]] \n",
    "                for word in evaluation_sents}\n",
    "max_count = {}\n",
    "for word in WORDS_LIST:\n",
    "    voa_sent = [sent.replace('\\n', '') for sent in voa_sentences[word]\n",
    "                if sent.replace('\\n', '') not in exists_sents[word]]\n",
    "    max_count[word] = len(voa_sent)\n",
    "    \n",
    "for word in voa_sentences:\n",
    "    if max_count[word] < AVG_NUM:\n",
    "        voa_sent = [sent.replace('\\n', '') for sent in voa_sentences[word]\n",
    "                if sent.replace('\\n', '') not in exists_sents[word]]\n",
    "        WORDS_LIST.remove(word)\n",
    "        TARGET_NUM -= max_count[word]\n",
    "        other_200sents[word] = voa_sent\n",
    "        \n",
    "\n",
    "AVG_NUM = math.ceil(TARGET_NUM / len(WORDS_LIST))\n",
    "for word in WORDS_LIST:\n",
    "    voa_sent = [[sent.replace('\\n', ''), ''] for sent in voa_sentences[word]\n",
    "                if sent.replace('\\n', '') not in exists_sents[word]]\n",
    "    examples = random.sample(voa_sent, AVG_NUM)\n",
    "    other_200sents[word].extend(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count(other_200sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/200_sentences.json', 'w') as f:\n",
    "#     f.write(json.dumps(other_200sents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
